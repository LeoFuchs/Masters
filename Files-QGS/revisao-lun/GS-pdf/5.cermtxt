2015 American Control Conference
Palmer House Hilton
July 1-3, 2015. Chicago, IL, USA
Security in Stochastic Control Systems:
Fundamental Limitations and Performance Bounds
Cheng-Zong Bai, Fabio Pasqualetti, and Vijay Gupta
Abstract- This work proposes a novel metric to characterize
the resilience of stochastic cyber-physical systems to attacks and
faults. We consider a single-input single-output plant regulated
by a control law based on the estimate of a Kalman filter.
We allow for the presence of an attacker able to hijack and
replace the control signal. The objective of the attacker is to
maximize the estimation error of the Kalman filter - which in
turn quantifies the degradation of the control performance - by
tampering with the control input, while remaining undetected.
We introduce a notion of -stealthiness to quantify the difficulty
to detect an attack when an arbitrary detection algorithm
is implemented by the controller. For a desired value of stealthiness,
we quantify the largest estimation error that
an attacker can induce, and we analytically characterize an
optimal attack strategy. Because our bounds are independent
of the detection mechanism implemented by the controller,
our information-theoretic analysis characterizes fundamental
security limitations of stochastic cyber-physical systems.
I. INTRODUCTION
Cyber-physical systems offer a variety of attack surfaces
arising from the interconnection of different technologies and
components. Depending on their resources and capabilities,
attackers generally aim to deteriorate the functionality of the
system, while avoiding detection for as long as possible [1].
Security of cyber-physical systems is a growing research
area where, recently, different attack strategies and defense
mechanisms have been characterized. While simple attacks
have a straightforward implementation and impact, such as
jamming control and communication channels [2], sophisticated
ones may degrade the functionality of a system more
severely [3], [4], and are more difficult to mitigate. In this
work we measure the severity of attacks based on their effect
on the control performance and on their level of stealthiness,
that is, the difficulty of being detected from measurements.
Intuitively, there exists a trade-off between the degradation
of control performance and the level of stealthiness of an
attack. Although this trade-off has previously been identified
for specific systems and detection mechanisms [5], [6], [7],
[8], a thorough analysis of the resilience of stochastic control
systems to arbitrary attacks is still missing.
Related works For deterministic cyber-physical systems the
concept of stealthiness of an attack is closely related to the
control-theoretic notion of zero dynamics [9]. In particular,
an attack is undetectable if and only if it excites only the zero
This material is based upon work supported in part by awards NSF ECCS1405330
and ONR N00014-14-1-0816. Cheng-Zong Bai and Vijay Gupta
are with the Department of Electrical Engineering, University of Notre
Dame, IN 46556, fcbai, vgupta2g@nd.edu . Fabio Pasqualetti is
with the Department of Mechanical Engineering, University of California,
Riverside, CA 92521, fabiopas@engr.ucr.edu .
978-1-4799-8684-2/$31.00 ©2015 AACC
195
dynamics of an appropriately defined input-output system
describing the system dynamics, the measurements available
to a security monitors, and the variables compromised by
the attacker [10], [11]. Thus, the question of stealthiness of
an attack has a binary answer in deterministic systems. For
stochastic cyber-physical systems, instead, the presence of
process and measurements noise offers a smart attacker the
additional possibility to tamper with sensor measurements
and control inputs within the acceptable uncertainty levels,
thereby making the detection task arbitrarily difficult.
Detectability of attacks in stochastic systems has received
only initial attention from the research community, and
there seem to be no agreement on an appropriate notion of
stealthiness. Most works in this area consider detectability
of attacks with respect to specific detection schemes, such
as the classic bad data detection algorithm [12]. In our
previous work [13], we proposed the notion of -marginal
stealthiness to quantify the stealthiness level with respect to
the class of ergodic detectors. With respect to [13], in this
work (i) we introduce a novel notion of stealthiness, namely
-stealthiness, that is independent of the attack detection
algorithm and thus provides a fundamental measure of the
stealthiness of attacks in stochastic control systems, and (ii)
we explicitly characterize detectability and performance of
-stealthy attacks.
Contributions The contributions of this paper are threefold.
First, we propose the notion of -stealthiness to quantify
detectability of attacks in stochastic cyber-physical systems.
Our metric is motivated by the Chernoff-Stein Lemma in
detection and information theories [14], and is universal, in
the sense that it is independent of any specific detection
mechanism employed by the controller. Second, we provide
an achievable bound for the degradation of the minimummean-square
estimation error caused by an -stealthy attack,
as a function of the system parameters, noise statistics,
and information available to the attacker. Third and finally,
we provide a closed-form expression of optimal -stealthy
attacks achieving the maximal degradation of the estimation
error. These results characterize the trade-off between performance
degradation that an attacker can induce, versus the
fundamental limit of the detectability of the attack.
We focus on single-input single-output systems with an
observer-based controller. However, our methods are general,
and applicable to multiple-input multiple-output systems via
a more involved technical analysis.
Paper organization Section II contains our mathematical
formulation of the problem and our model of attacker. In
Section III we discuss our metric to quantify the stealthiness
level of an attack. The main results of this paper are presented
in Section IV, including a characterization of the largest
perturbation caused by an -stealthy attack, and a closedform
expression of optimal -stealthy attacks. Section V
contains our illustrative examples and numerical results.
Finally, Section VI concludes the paper.
II. SYSTEM AND ATTACK MODELS
In this section we detail our system and attack models.
Throughout the paper, we let xij denote the sequence
fxngjn=i, and x N ( ; 2) a Gaussian random variable
with mean and variance 2.
A. System model
We consider the single-input single-output time-invariant
system described by
xk+1 = axk + uk + wk;
yk = cxk + vk;
(1)
where a; c 2 R, c 6= 0, w11 and v11 are random sequences
representing process and measurement noise, respectively.
We assume the sequences w11 and v11 to be independent and
identically distributed (i.i.d.) Gaussian processes with wk
N (0; w2), vk N (0; v2) for all k > 0. The control input uk
is generated based on a causal observer-based control policy,
that is, uk is a function of the measurement sequence y1k.
In particular, the controller employes a Kalman filter [15],
[16] to compute the Minimum-Mean-Squared-Error (MMSE)
estimate x^k+1 of xk+1 from the measurements y1k. The
Kalman filter reads as
x^k+1 = ax^k + Kk(yk
cx^k) + uk;
(2)
where the Kalman gain Kk and the mean squared error
Pk+1 , E (x^k+1 xk+1)2 can be calculated by the
recursions
Kk =
acPk
c2Pk + 2
v
;
Pk+1 = a2Pk +
2
w
a2c2P 2
k :
c2Pk + 2
v
with the initial condition x^1 = E[x1] = 0 and P1 = E[x12].
If the system (1) is detectable (i.e., jaj < 1 or c 6= 0),
then the Kalman filter converges to the steady state in the
sense that limk!1 Pk = P exists [16], where P can be
obtained uniquely through the algebraic Riccati equation. For
the ease of presentation, we assume that P1 = P . Hence,
we obtain a steady state Kalman filter with Kalman gain
Kk = K and Pk = P at every time step k. The sequence
z11 calculated as zk , yk cx^k is called the innovation
sequence. Since we consider steady state Kalman filtering,
the innovation sequence is an i.i.d. Gaussian process with
zk N (0; c2P + v2).
B. Attack model
We consider an attacker capable of hijacking and replacing
the control input u11 with an arbitrary signal u~11. Assume
that the attacker knows the system parameters a; c; w2; v2.
Let Ik denote the information available to the attacker
at time k. The attack input u~11 is constructed based on
the system parameters and the attacker information pattern,
which satisfies the following assumptions:
(A1) the attacker knows the control input uk, that is, uk 2
Ik at all times k;
(A2) the information available to the attacker is nondecreasing,
that is, Ik Ik+1;
(A3) Ik is independent of the wk1 and vk1+1 due to causality.
Attack scenarios satisfying assumptions (A1)-(A3) include:
(i) the attacker knows the control input, that is, Ik =
fu1kg;
(ii) the attacker knows the control input and the state, that
is, Ik = fu1k; x1kg;
(iii) the attacker knows the control input and the (delayed)
measurements received by the controller, that is, Ik =
fu1k; y~1k dg with d 0;
(iv) the attacker knows the control input and take additional
measurements yk, that is, Ik = fu1k; y1kg.
Let y~11 be the sequence of measurements received by the
controller in the presence of the attack u~11. Then, y~11 is
generated by the dynamics
xk+1 = axk + u~k + wk;
y~k = cxk + vk:
(3)
Notice that, because the controller is unaware of the attack,
the corrupted measurements y~11, and hence the attack input
u~11, drive the Kalman filter (2) as an external input. Let x~^1
1
be the estimate of the Kalman filter (2) in the presence of
the attack u~11, which is obtained from the recursion
x~^k+1 = ax~^k + Kz~k + uk;
with innovation is z~k , y~k cx~^k. Notice that (i) the estimate
x~^k+1 is sub-optimal, because it is obtained by assuming the
nominal control input, whereas the system is driven by the
attack input, and (ii) the random sequence z~1 need neither
1
be stationary, nor zero mean, white or Gaussian, because the
attack input is arbitrary.
Let P~k+1 = E[(x~^k+1 xk+1)2] be the second moment
of the estimation error x~^k+1 xk+1, and assume that the
attacker aims to maximize P~k+1. We consider the asymptotic
behavior of P~k+1 to measure the performance degradation induced
by the attacker. Since the attack sequence is arbitrary,
the sequence P~11 may diverge. Accordingly, we consider
the limit superior of arithmetic mean of the sequence P~11 as
given by
k
P~ , lim sup 1 X P~n:
k!1 k n=1
Notice that if the sequence P~1 is convergent, then
1
limk!1 P~k+1 = P~, which equals the Cesa`ro mean1 [14].
1The steady state assumption is made in order to obtain an i.i.d. innovation
sequence. If the Kalman filter starts from an arbitrary initial condition P1,
then the innovation sequence is an independent, asymptotically identically
distributed, Gaussian process. This identity guarantees that the results for
the case of non-steady state Kalman filter coincide with the main results
(i.e., Theorem 1 and Theorem 2) in this paper.
196
III. ATTACK STEALTHINESS FOR STOCHASTIC SYSTEMS
In this section we motivate and define our notion of stealthiness
of attacks. Notice that the system (3) with w2 =
0 and v2 = 0 (i.e., deterministic single-input single-output
system) features no zero dynamics. Hence, every attack
would be detectable [10]. However, the stochastic nature
of the system provides an additional degree of freedom to
the attacker, because the process noise and the measurement
noise induce some uncertainty in the measurements. Building
on this idea, we now formally define attack stealthiness. Consider
the problem of detecting an attack from measurements.
Notice that the detector must rely on the statistical properties
of the received measurement sequence as compared with
their expected model in (1). This can be formulated by the
following binary hypothesis testing problem:
H0 : No attack is in progress (the controller receives y1k);
H1 : Attack is in progress (the controller receives y~1k).
Suppose that a detector is employed by the controller. Let
pkF be the probability of false alarm (decide H1 when H0
is true) at time k and let pkD be the probability of detection
(decide H1 when H1 is true) at time k. In detection theory,
the performance of the detector can be characterized by the
trade-off between pkF and pD, namely, the Receiver Operatk
ing Characteristic (ROC) [17]. From the ROC perspective,
the attack that is hardest to detect is the one for which, at
every time k, there exists no detector that performs better
than a random guess (e.g., to make a decision by flipping a
coin) independent of the hypothesis. If a detector makes a
decision via a random guess independent of the hypothesis,
then the operating point of the ROC satisfies pkF = pD.
k
Definition 1: (Strict stealthiness) The attack u~11 is
strictly stealthy if there exists no detector such that pkF < pD
k
at any k > 0.
The reader may argue that strict stealthiness is a too
restrictive notion of stealthiness for an attacker, and it significantly
limits the set of stealthy attacks. In fact, the attacker
may be satisfied with attack inputs that are difficult to detect,
in the sense that the detector would need to collect more
measurements to make a decision with a desired operating
point of ROC. Although it is impractical to compute the exact
values of these two probabilities for an arbitrary detector at
every time k, we are able to apply the techniques in detection
theory and information theory to obtain bounds for pkF and
pD. A classical example is the Chernoff-Stein Lemma [14].
k
This lemma characterizes the asymptotic exponent of pF ,
k
while pD can be arbitrary. Motivated by Chernoff-Stein
k
Lemma, we propose the following notion of -stealthiness.
Definition 2: ( -stealthiness) Let > 0 and 0 < <
1. The attack u~11 is -stealthy if there exists no detector
such that the following two conditions can be satisfied
simultaneously:
(i) The detector operates with 0 < 1 pkD at all times
k.
(ii) The probability of false alarm pkF converges to zero
exponentially fast with rate greater than as k grows.
197
In other words, for any detector that satisfies 0 < 1 pD
k
for all times k, it holds
lim sup
k!1
1
k
log pkF
:
Definition 2 provides a characterization of the detectability
for -stealthy attacks. We now provide a sufficient condition
and a necessary condition for an attack to be -stealthy,
which rely on the Kullback-Leibler divergence (or relative
entropy) [14], [18] defined as follows.
Definition 3: (Kullback-Leibler divergence) Let x1k and
y1k be two random sequences with joint probability density
functions fxk and fyk , respectively. The Kullback-Leibler
1 1
Divergence (KLD) between x1k and y1k equals
D x1k y1k =
Z 1
1
log ffxy1k1k (( 11kk)) fx1k ( 1k)d 1k:
The KLD is a non-negative measure of the dissimilarity
between two probability density functions. It should be
iosbgseernveerdalltyhantoDtsyxm1kmye1ktric=,th0atifisf, xD1k =x1kfyy1k1k. A6=lsoD, thye1k KxL1kD.
Using the Chernoff-Stein Lemma, we can provide a sufficient
condition for an attack to be -stealthy.
Lemma 1: (Sufficient condition for -stealthiness) Let
y~1 be the random sequence generated by the attack u~11.
1
Let y~11 be ergodic and satisfy
lim
k!1 k
1
D y~1k y1k
:
Then, the attack u~11 is -stealthy.
Proof: We apply the Chernoff-Stein Lemma for ergodic
measurements (e.g., see [19]). For such an attack u~11, given
0 < 1 pkD where 0 < < 1, the best achievable
exponent of pkF is given by limk!1 k1 D y~1k y1k . For any
detector, we obtain
lim sup
k!1
1
k
log pkF
lim
k!1 k
1
D y~1k y1k
:
By Definition 2, the attack is -stealthy.
Next, we provide a necessary condition for an attack to
be -stealthy.
Lemma 2: (Necessary condition for -stealthiness) Let
the attack u~11 be -stealthy. Then
(4)
(5)
(6)
lim sup
k!1
1
k
D y~1k y1k
:
(7)
Proof: The proof can be found in [20].
We conclude this section with a method to compute the
KLD between the sequences y~1k and y1k. For observed-based
controllers, note that zk and z~k are invertible functions of y1k
and y~1k, respectively. Recall from the invariance properties of
the KLD [18] that, for every k > 0,
D y~1k y1k
= D z~1k z1k :
Moreover, z11 is an i.i.d. Gaussian random sequence with
zk N (0; z2). From (5) we obtain
1
k
D z~1k z1k =
1
k
h z~1k + 12
log(2
z2) +
(8)
where h z~1k = R 11 fz~1k ( 1k) log fz~1k ( 1k)d 1k is the differential
entropy of z~1k [14].
IV. PERFORMANCE BOUNDS AND LIMITATIONS
We are interested in the maximal performance degradation
P~ that an -stealthy attack may induce. We present such a
fundamental limit in two parts: the converse statement that
gives an upper bound for P~ as induced by an -stealthy
attack, and the achievability result that provides an attack
that achieves the upper bound of the converse result.
Theorem 1: (Converse) Consider the system stated in (1).
Let the sequence I11 satisfy assumptions (A1)-(A3). Let u~1
1
be an -stealthy attack generated by I11. Then, the estimation
error induced by the attacker satisfies
1 Xk E z~2
k 2 zn2 ;
n=1
k
P~ = lim sup 1 X P~n
k!1 k n=1
( )P +
( ( )
1) v2
c2
where the function
: [0; 1) ! [1; 1) is such that
(D) = 2D + 1 + log (D):
Proof: Observe that z~k = y~k cx~^k = c(xk
and (xk x~^k) is independent of vk. We have
x~^k) + vk,
E[z~k2] = c2P~k +
v2:
Since v2 is a constant and c2 > 0, we can represent P~ in
terms of E[z~k2]. From (8), we have
1
2
1
2
1
2
log(2
log(2
log(2
1
k
z2) +
h z~1k
k
z2) + 1 X h(z~n)
k
z2) +
n=1
n=1
k
1 X 1 log 2 eE[z~n2]
k 2
1 1 Xk E[z~n2]
2 k z2
=
D z~1k z1k
D z~1k z1k
D z~1k z1k
n=1
1
k
1
k
1
k
1
k
1
k
(9)
(10)
(11)
(12)
(13)
(14)
198
=
D z~1k z1k + 21
D z~1k z1k + 21
+
+
1
2
1
2
log
log
k 1
Y E[z~n2] ! k
2
z
n=1
1 X E[z~n2] !
k
k z2
n=1
;
where the inequalities (12) is due to the subadditivity of
differential entropy [14, Corollary 8.6.1], the inequality (13)
is a consequence of the maximum entropy theorem [14,
Theorem 8.6.5], and the inequality (14) follows from the
arithmetic mean and geometric mean inequality. Consider
the following maximization problem
maxx2R
subject to
x;
1 x
2
D
1
2
12 log x;
where D 0. Since the logarithm function is concave, the
feasible region of x in (15) is a closed interval upper bounded
by (D) as defined in (10); see Fig. 1. Thus, the maximum
in (15) is (D). By (14) and the maximization problem (15),
we obtain
k
1 X E[z~n2]
k z2
n=1
1
k
D z~1k z1k
:
From (11) and (16) we obtain'
P~ = likm!s1up k1 nX=k1 P~n = likm!s1up k1 Xk E[z~n2c]2
=
lim sup
k!1
( ) z2
c2
k1 D z~1k z1k
c2
2
v ;
c2
lim supk!1 k1 D z~1k z1k
2
v
2
z
15
10
)
D
¯δ(5
n=1
2
v
2
z
(15)
2
v
(16)
(17)
(18)
(19)
where the inequality (17) can be obtained by the definition
of limit superior, the equality (18) is due to the continuity
and monotonicity of the function , and the inequality (19)
follows from Lemma 2. Finally, the desired result is obtained
by substituting z2 = c2P + v2 into (19).
0
0
12 log x
1
x
12x − D − 1
2
δ¯(D)
00
1
2
D
3
4
5
Fig. 1. Illustrations for the optimization problem (15) and the function :
[0; 1) ! [1; 1) defined in (10). Notice that the function is continuous
and monotonically increasing.
Remark 1: (Effect of strictly stealthy attacks) Strictly
stealthy attacks do not degrade the performance of the
Kalman filter. To see this, notice that if an attack is strictly
stealthy then D y~1k y1k = 0 for all k > 0 (this is
a consequence of Definition 1 and the Neyman-Pearson
Lemma [17]). Moreover, by using (11), (16), and the fact
that (0) = 1 whenever D z~1k z1k = 0 for all k > 0,
we obtain E[z~k2] = c2P~k + v2 c2P + v2. Consequently
P~k P , that is, the mean squared error of the Kalman filter
under attack is less or equal to the minimum mean squared
error in the absence of attacks.
In the next theorem we construct an -stealthy attack that
achieves the upper bound in Theorem 1.
Theorem 2: (Achievability) Let2 11 be an i.i.d. sequence
of random variables k N 0; c2z ( ( ) 1) independent
of fx1 ; y~1 ; I1kg, and let the attack be defined as
k k
u~k = uk
(a
Kc) k 1 + k;
(20)
with 0 = 0. Then, the attack u~11 is -stealthy and it achieves
the converse result in Theorem 1, that is,
P~ = lim 1 Xk P~n = ( )P + ( ( )
k!1 k n=1
c2
1) v2
;
where the function : [0; 1) ! [1; 1) satisfies (10).
Proof: For the ease of analysis and without affecting
generality, we assume that the attack u~1 is generated by
1
an attacker with the information pattern I11, with Ik =
fu1k; y~1 g for every k > 0.
k
We first show that the upper bound (9) is achieved by the
attack. Notice that the attacker implements the Kalman filter
x^kA+1 = ax^kA + KzkA + u~k with the initial condition x^1A = 0
where zkA = y~k cx^kA. Thus, x^kA+1 is the MMSE estimate of
the state with the mean squared error E[(x^kA+1 xk+1)2] = P
when Ik is given. Note that z~k can be expressed as
z~k = y~k
cx~^k = y~k
cx^kA + c(x^kA
x~^k) = zk
A
ce~k; (21)
x^kA. In addition, the dynamics of e~k are
where e~k = x~^k
given by
e~k+1 = (ax~^k + Kz~k + uk)
(ax^kA + KzkA + u~k)
= (a
Kc)e~k + (a
Kc) k 1
k;
(22)
and the initial condition is e~1 = 0. Equation (22) implies
that e~k+1 = k for every k > 0. Further, for every k > 0,
P~k+1 can be expressed as
P~k+1 = E (x~^k+1
A A
x^k+1 + x^k+1
x^kA+1)2 + E (x^kA+1
x^k+1)(x^kA+1
A
xk+1)2
xk+1)
xk+1)2
= E (x~^k+1
+ 2E (x~^k+1
= E (e~k+1)2 + P
2
= z ( ( )
1) + P
c2
= ( )P +
( ( )
c2
1) v2
:
In (23), the fact E (x~^k+1 x^kA+1)(x^kA+1 xk+1) = 0 is
due to the principle of orthogonality, i.e., all the random
variables generated by Ik is independent of the estimation
error (x^kA+1 xk+1) of the MMSE estimate. Hence, the upper
bound of P~ in (9) is achieved by this attack.
Now we show that the attack u~11 is -stealthy. From (21)
and (22), we obtain z~k = zA + c k 1. Since fzkAgk1=1 is
k
an i.i.d. random sequence with zkA N (0; z2), the random
sequence z~11 is i.i.d. Gaussian with z~k N (0; ( ) z2). For
(23)
(24)
199
every k > 0, we can calculate the KLD as
k
1 X
k
n=1
k
D y~1k y1k = k1 X
n=1
D z~1k z1k
k
= 1 X
k
1
2
n=1
1
2
1
2
=
=
log 2 e ( ) z2 +
log(2
z2) +
1
2
( ) z2
2 z2
log ( ) +
( )
1
2
where the differential entropy of z~1k is given by h(z~1k) =
Pkn=1 h(z~n) = k2 log 2 e ( ) z2 because z~11 is an i.i.d.
Gaussian sequence. In this case, y~1 is ergodic. From
1
Lemma 1, the attack u~11 is -stealthy. To conclude the
proof, notice that the attack (20) can be generated by any
information pattern satisfying (A1)-(A3).
Remark 2: (Attacker information pattern) As a counterintuitive
fact, Theorem 1 and Theorem 2 imply that knowledge
of the system state does not increase the performance
degradation induced by an attacker. In fact, the only critical
piece of information for the attacker is the nominal control
input u11. It should be also noticed that knowledge of the
nominal control input may not be necessary for different
system and attack models. For instance, in the case the
control input is transmitted via an additive channel, the
attacker may achieve the upper bound (9) exploiting the
linearity of the system, and without knowing the nominal
control input.
Remark 3: (Properties of the optimal attack) Recall
that we make no assumption on the form of attacks. Yet,
Theorem 2 implies that the random sequence z~1 generated
1
the optimal attack remains i.i.d. Gaussian with zero mean.
This property follows from the fact that the inequalities (12),
(13) and (14) hold with equalities in the case of optimal
attacks.
V. NUMERICAL RESULTS
We now present numerical results to illustrate the fundamental
performance bounds derived in Section IV. The
following results are stated based on the ratio P~=P , which
can be interpreted as the attacker gain. If the ratio P~=P = 1,
then the attacker can induce no degradation of the mean
squared error. In Theorem 1 and Theorem 2 we characterize
how an attacker must compromise between stealthiness and
performance degradation at the system level. To illustrate
such a trade-off, in Fig. 2 we report the ratio P~=P as
a function of the attack stealthiness , for given system
parameters.
In Fig. 3 we illustrate the relation between the attacker
gain P~=P and the quality of the measurements, as measured
by c2= v2. As expected, for a desired level of stealthiness,
the attacker gain is smaller for larger values of c2= v2.
Consider now the limiting situation of an unstable system
with c2= v2 ! 0+. In this case the open loop unstable system
is not detectable and thus P ! 1. By taking the limit of
(9) as c2= v2 ! 0+ we obtain P~ ! 1. In accordance with
1
2
0
3
4
5
Fig. 2. This figure shows that attack stealthiness ( ) and performance
degradation at the system level (P~=P ) are competing objectives. The
degradation P~ is induced by the optimal -stealthy attack in (20). The system
parameters are a = 2, c = 1, w = 0:5, and v2 = 0:1.
2
0 = 0.5
0 = 1
0 = 2
0 = 4
2
4
c2/σv2
6
8
10
Fig. 3. This figure shows that, for a desired value of stealthiness, the larger
the quality of measurements (c2= v2) the smaller the attacker gain (P~=P ).
The system parameters are a = 2 and w2 = 0:5, and the degradation P~ is
induced by the optimal -stealthy attack in (20).
these results, Fig. 3 shows that P~=P remains bounded as
c2= v2 ! 0+.
Similarly, we consider the limiting situation of a stable
system with c2= v2 ! 0+. The attacker gain P~=P as a
function of c2= v2 is reported in Fig. 4. It can be observed
that P~=P grows unbounded as c2= v2 ! 0+. In fact, since
the system is stable, the mean squared error of the Kalman
filter P is bounded for all c2= v2 0. On the other hand, by
taking the limit of (9) we observe that P~ goes to infinity as
c2= v2 ! 0+.
VI. CONCLUSION
This work characterizes fundamental limitations and performance
bounds for the security of stochastic control systems.
The scenario is considered where the attacker knows
the system parameters and noise statistics, and is able to
hijack and replace the nominal control input. We propose a
notion of -stealthiness to quantify the difficulty to detect an
attack from measurements, and we characterize the maximal
degradation of the control performance induced by an stealthy
attack. Our study reveals that an -stealthy attacker
only need to know the nominal control input to cause the
largest performance degradation in Kalman filtering.
REFERENCES
[1] A. Teixeira, D. Pe´rez, H. Sandberg, and K. H. Johansson, “Attack
models and scenarios for networked control systems,” in Proc. of the
16
12
/P 8
˜
P
4
0
0
16
14
12
10
P
/
˜P 8
6
4
2
0
50
40
30
P
/
˜
P20
10
0
0
0 = 0.5
0 = 1
0 = 2
0 = 4
2
4
6
8
10
c2/σv2
200
Fig. 4. This figure shows the tradeoff between performance degradation
at the system level (P~=P ) and the quality of measurements (c2= v2) for a
stable system. The system parameters are a = 0:5 and w2 = 0:5, and the
degradation P~ is induced by the optimal -stealthy attack in (20). Notice
that, contrarily to the case of unstable system in Fig. 3, the attacker gain
grows unbounded as c2= v2 approaches zero.
1st international conference on High Confidence Networked Systems.
ACM, 2012, pp. 55-64.
[2] H. S. Foroush and S. Mart´ınez, “On multi-input controllable linear
systems under unknown periodic dos jamming attacks.” in SIAM Conf.
on Control and its Applications. SIAM, 2013, pp. 222-229.
[3] R. S. Smith, “A decoupled feedback structure for covertly appropriating
networked control systems,” Network, vol. 6, p. 6, 2011.
[4] Y. Mo and B. Sinopoli, “Secure control against replay attacks,” in 47th
Annual Allerton Conference. IEEE, 2009, pp. 911-918.
[5] O. Kosut, L. Jia, R. J. Thomas, and L. Tong, “Malicious data attacks
on the smart grid,” Smart Grid, IEEE Trans. on, vol. 2, no. 4, pp.
645-658, 2011.
[6] Y. Liu, P. Ning, and M. K. Reiter, “False data injection attacks against
state estimation in electric power grids,” ACM Trans. on Information
and System Security, vol. 14, no. 1, p. 13, 2011.
[7] C. Kwon, W. Liu, and I. Hwang, “Security analysis for cyber-physical
systems against stealthy deception attacks,” in American Control
Conference (ACC), 2013. IEEE, 2013, pp. 3344-3349.
[8] Y. Mo, R. Chabukswar, and B. Sinopoli, “Detecting integrity attacks
on scada systems,” IEEE Transactions on Control Systems Technology,
vol. 22, no. 4, pp. 1396-1407, 2014.
[9] G. Basile and G. Marro, Controlled and Conditioned Invariants in
Linear System Theory. Prentice Hall, 1991.
[10] F. Pasqualetti, F. Do¨rfler, and F. Bullo, “Attack detection and identification
in cyber-physical systems,” IEEE Trans. Autom. Control, vol. 58,
no. 11, 2013.
[11] H. Fawzi, P. Tabuada, and S. Diggavi, “Secure estimation and control
for cyber-physical systems under adversarial attacks,” IEEE Trans. on
Automatic Control, vol. 59, no. 6, pp. 1454-1467, 2014.
[12] S. Cui, Z. Han, S. Kar, T. T. Kim, H. V. Poor, and A. Tajer,
“Coordinated data-injection attack and detection in the smart grid:
A detailed look at enriching detection solutions,” Signal Processing
Magazine, IEEE, vol. 29, no. 5, pp. 106-115, 2012.
[13] C.-Z. Bai and V. Gupta, “On Kalman filtering in the presence of a
compromised sensor: Fundamental performance bounds,” in American
Control Conference (ACC), Portland, OR, June 2014, pp. 3029-3034.
[14] T. M. Cover and J. A. Thomas, Elements of Information Theory,
2nd ed. Wiley, 2006.
[15] R. E. Kalman, “A new approach to linear filtering and prediction
problems,” J. of Basic Engineering, vol. 82, no. 1, pp. 35-45, 1960.
[16] T. Kailath, A. H. Sayed, and B. Hassibi, Linear Estimation. Prentice
Hall, 2000.
[17] H. V. Poor, An introduction to signal detection and estimation, 2nd ed.
New York: Springer-Verlag, 1998.
[18] S. Kullback, Information theory and statistics. Courier Dover, 1997.
[19] Y. Polyanskiy and Y. Wu, Lecture notes on Information Theory. MIT
(6.441), UIUC (ECE 563), 2012-2013.
[20] C.-Z. Bai, F. Pasqualetti, and V. Gupta, “Notes on security in
stochastic control systems: Fundamental limitations and performance
bounds (ACC 2015),” http://www3.nd.edu/ vgupta2/research/
publications/ACC2015Note.pdf.